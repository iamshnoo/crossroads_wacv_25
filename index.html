<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="Cultural adaptation of outputs from Multimodal LLMs">
  <meta name="keywords" content="LLM, Cultural Adaptation, Multimodal, Cultural Awareness">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Global Gallery</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
    rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link href="path/to/prism.css" rel="stylesheet" />
  <link rel="icon" href="./static/images/favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="path/to/prism.js"></script>

</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Crossroads of Continents: Automated Artifact Extraction for
              Cultural
              Adaptation with Large Multimodal Models</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://iamshnoo.github.io">Anjishnu Mukherjee</a></a>,
                <!-- <sup>1</sup>, -->
              </span>
              <span class="author-block">
                <a href="https://zziwei.github.io">Ziwei Zhu</a></a>,
                <!-- <sup>1</sup>, -->
              </span>
              <span class="author-block">
                <a href="https://nlp.cs.gmu.edu/author/antonios-anastasopoulos/">Antonios
                  Anastasopoulos</a></a>
                <!-- <sup>1</sup> -->
              </span>
            </div>

            <!-- <div class="is-size-5 publication-authors">
            <span class="author-block">George Mason
            University</span><br>
            <span class="author-block"></span><img src="static/images/GMUNLP.png" alt="GM NLP Logo" class="publication-logo"/></span>
          </div> -->
            <div class="is-size-5 publication-authors">
              <span class="author-block">George Mason University</span><br>
              <!-- <span class="author-block"><sup>2</sup>University of Washington</span><br> -->
              <span class="author-block"></span><img src="static/images/gmu-2.png" alt="GM NLP Logo"
                class="publication-logo" /></span>
              <!-- <span class="author-block"></span><img src="static/images/UW-logo.png" alt="UW Logo" -->
              <!-- class="publication-logo" /></span> -->
              <!-- <div style="display: flex; align-items: center;">
                <object data="static/images/gmu-2.pdf" type="application/pdf" width="150" height="150">
                    <p>GMU Logo</p>
                </object>
                <object data="static/images/UW-logo.pdf" type="application/pdf" width="150" height="150">
                    <p>UW Logo</p>
                </object>
            </div> -->
            </div>

          </div>
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="publication-links">
          <span class="link-block">
            <a href="https://www.arxiv.org/pdf/2407.02067"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fas fa-file-pdf"></i>
              </span>
              <span>PDF</span>
            </a>
            <!-- <a href="static/images/naacl_global_gallery.pdf"
                    class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a> -->
          </span>
          <!-- Code Link. -->
          <span class="link-block">
            <a href="https://github.com/iamshnoo/crossroads"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fab fa-github"></i>
              </span>
              <span>Code</span>
            </a>
          </span>
          <!-- Dataset Link. -->
          <span class="link-block">
            <a href="https://huggingface.co/datasets/iamshnoo/dallestreet"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="far fa-file-alt"></i>
              </span>
              <span>Data</span>
            </a>
          </span>
          <!-- Video Link. -->
          <!-- <span class="link-block">
            <a href="https://youtu.be/wU1pGizzmY0"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fab fa-youtube"></i>
              </span>
              <span>Video</span>
            </a>
          </span> -->
        </div>
        <!-- Slide Link. -->
        <span class="link-block">
          <a href="./static/images/wacv-2025-presentation.pdf"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <i class="fas fa-file-powerpoint"></i>
            </span>
            <span>Slides</span>
          </a>
        </span>
        <!-- Poster Link. -->
        <span class="link-block">
          <a href="./static/images/wacv-2025-poster.pdf" class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <i class="fas fa-image"></i>
            </span>
            <span>Poster</span>
          </a>
        </span>

      </div>
    </div>
    </div>
    </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img id="teaser" src="./static/images/fig1-continents-crossroads.png" alt="Teaser Image" height="50%">
        <h2 class="subtitle has-text-centered">
          <!-- <span class="dnerf">WeatHub</span> is a step towards measuring biases
        across languages and cultures by providing a comprehensive multilingual
        benchmark. -->
        Models associate countries with cultural artifacts <br> which can be identified and replaced for cultural adaptation.
        </h2>
      </div>
    </div>
  </section>


  <section class="section" id="Abstract">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <!-- Coming Soon -->
            <p>
              We present a comprehensive three-phase study to examine (1) the cultural understanding of Large
              Multimodal Models (LMMs) by introducing Dalle Street, a
              large-scale dataset generated by DALL-E 3 and
              validated by humans, containing 9,935 images of 67 countries and 10 concept classes; (2) the
              underlying implicit and potentially stereotypical cultural associations with a cultural artifact
              extraction task; and (3) an approach to adapt cultural representation in an image based on extracted
              associations using a modular pipeline, CultureAdapt. We find disparities in cultural understanding at
              geographic sub-region levels with both open-source (LLaVA) and closed-source (GPT-4V) models on
              Dalle Street and other existing benchmarks, which we try to understand using over 18,000 artifacts that
              we identify in association to different countries. Our findings reveal a nuanced picture of the cultural
              competence of LMMs, highlighting the need to develop culture-aware systems.
            </p>
            <!-- <p>
            Human biases are ubiquitous but not uniform: disparities exist
            across linguistic, cultural, and societal borders.
            As large amounts of recent literature suggest, language models (LMs)
            trained on human data can reflect and often amplify the effects of
            these social biases. However, the vast majority of existing studies
            on bias are heavily skewed towards Western and European languages.
          </p>
          <p>
            In this work, we scale the Word Embedding Association Test (WEAT)
            to 24 languages, enabling broader studies and yielding interesting
            findings about LM bias. We additionally enhance this data with
            culturally relevant information for each language, capturing local
            contexts on a global scale. Further, to encompass more widely
            prevalent societal biases, we examine new bias dimensions across
            toxicity, ableism, and more. Moreover, we delve deeper into the
            Indian linguistic landscape, conducting a comprehensive regional
            bias analysis across six prevalent Indian languages. Finally, we
            highlight the significance of these social biases and the new
            dimensions through an extensive comparison of embedding methods,
            reinforcing the need to address them in pursuit of more equitable
            language models.
          </p> -->
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <!-- <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/wU1pGizzmY0?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
        <!--/ Paper video. -->
      </div>
  </section>

  <!-- <section class="section" id="Main contributions">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full">
          <div class="content has-text-centered">
            <h2 class="title is-3">Main Contributions</h2>
            <img src="static/images/naacl_results.png" alt="Contributions Image" style="max-width: 100%;">
          </div>
        </div>
      </div>
    </div>
  </section> -->


  <!-- <section class="section" id="Main contributions">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Biases in traditional WEAT dimensions</h2>
          <p>
            <a
            href="https://researchportal.bath.ac.uk/en/publications/semantics-derived-automatically-from-language-corpora-necessarily">Semantics
            derived automatically from language corpora contain human-like
            biases. </a> by Caliskan et al. introduced the WEAT test for
            measuring implicit biases in word embeddings and further work from
            other researchers have shown that 6 of the 10 original categories
            can be somewhat replicated in multilingual settings.
          </p>
          <p>
            Our work is one of the most comprehensive in this aspect, covering
            24 languages including many from the global south which usually do
            not receive much attention in studies about bias.
          </p>

          <img id="teaser" src="./static/images/teaser.png" alt="Teaser
          Image" height="100%">
        </div>
      </div>
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Human-centered Contemporary Biases</h2>
          <p>
            We further build on this to propose 5 (+2) new dimensions of bias to
            cover contemporary aspects like ableism, toxcitiy, sexuality,
            immigration and education. We explore the dimensions of sexuality
            and ableism from the angle of valence (associations with pleasant
            and/or unpleasant words) resulting in the 2 new angles.
          </p>
            <img id="teaser" src="./static/images/new_biases_table.png"
            alt="Table for New bias dimensions" height="100%">
            <img id="teaser" src="./static/images/new_biases_fig.png"
            alt="Heatmap of new bias dimensions" height="100%">
          </p>
        </div>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Multilingual vs Monolingual Models</h2>
          <p>
            We find that the biases reflected in monolingual models tend to be
            more aligned with human biases. Multilingual models trained on data
            from multiple languages at the same time may not be as accurate at
            reflecting cultural biases for each of those languages as accurately
            as monolingual models. This leads to the idea that it may be more
            useful to explore monolingual models than multilingual ones for
            understanding biases in different cultures and their correlation
            with language.
          </p>
          <img id="teaser" src="./static/images/mono_multi.png" alt="Teaser Image" height="100%">
        </div>
      </div>
      <div class="column">
        <div class="content">
          <h2 class="title is-3">The Need for Human translations</h2>
          <p>
            We find WEAT effect sizes from human translations are almost always
            larger than those from machine translations, across embeddings from
            static and contextual models, suggesting that sole reliance on MT
            may not suffice for bias evaluation across languages.
          </p>
            <img id="teaser" src="./static/images/ht_better.png" alt="Teaser Image" height="100%">
          </p>
          <p>
            Therefore, we recommend utilizing human-annotated data for an
            accurate and fair assessment of bias across languages instead
            of solely relying on machine translation systems.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="Code">
  <div class="container is-max-desktop content">
    <h2 class="title">Code</h2>
    <p>
      Our data and code are available. The recommended approach for using the
      data is via huggingface datasets. The snippet below is representative of
      the steps required to load WEAT data in any of the languages or dimensions
      discussed in our paper.
    </p>
    <pre><code class="language-python">
from datasets import load_dataset

dataset = load_dataset("iamshnoo/WEATHub")

example = dataset["original_weat"][0]

target_set_1 = example["targ1.examples"]
target_set_2 = example["targ2.examples"]
attribute_set_1 = example["attr1.examples"]
attribute_set_2 = example["attr2.examples"]
    </code></pre>

    <p>
      The HuggingFace dataset also has an extensive Dataset Card describing
      all the common questions about the dataset and its usage.
    </p>
  </div>
</section>


<section class="section" id="Contributing">
  <div class="container is-max-desktop content">
    <h2 class="title">Contributing</h2>
    <p>
      If a language you are interested in is not included in our dataset, please
      consider contributing to our dataset. To do so, simply send an email to
      <a href="mailto:amukher6@gmu.edu">amukher6 at gmu dot edu</a> with
      [WEATHub] in the subject line. We will share a link to your email where
      you can add your contributions!
    </p>

    <p>
      The languages we currently have in WEATHub (our dataset) are:
    </p>
    <div class="language-buttons">
      <span class="language-button arabic">Arabic (ar)</span>
    <span class="language-button bengali">Bengali (bn)</span>
    <span class="language-button kurdish-sorani">Sorani Kurdish (ckb)</span>
    <span class="language-button danish">Danish (da)</span>
    <span class="language-button german">German (de)</span>
    <span class="language-button greek">Greek (el)</span>
    <span class="language-button english">English (en)</span>
    <span class="language-button spanish">Spanish (es)</span>
    <span class="language-button persian">Persian (fa)</span>
    <span class="language-button french">French (fr)</span>
    <span class="language-button hindi">Hindi (hi)</span>
    <span class="language-button italian">Italian (it)</span>
    <span class="language-button japanese">Japanese (ja)</span>
    <span class="language-button korean">Korean (ko)</span>
    <span class="language-button kurdish-kurmanji">Kurmanji Kurdish (ku)</span>
    <span class="language-button marathi">Marathi (mr)</span>
    <span class="language-button punjabi">Punjabi (pa)</span>
    <span class="language-button russian">Russian (ru)</span>
    <span class="language-button telugu">Telugu (te)</span>
    <span class="language-button thai">Thai (th)</span>
    <span class="language-button tagalog">Tagalog (tl)</span>
    <span class="language-button turkish">Turkish (tr)</span>
    <span class="language-button urdu">Urdu (ur)</span>
    <span class="language-button vietnamese">Vietnamese (vi)</span>
    <span class="language-button mandarin-chinese">Mandarin Chinese (zh)</span>
      <!-- Add more languages as needed -->
  <!-- </div>
  </section> -->


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>

      <p>
        If you find our work useful, please cite it!
      </p>

      <pre><code>@misc{mukherjee2024crossroadscontinentsautomatedartifact,
        title={Crossroads of Continents: Automated Artifact Extraction for Cultural Adaptation with Large Multimodal Models},
        author={Anjishnu Mukherjee and Ziwei Zhu and Antonios Anastasopoulos},
        year={2024},
        eprint={2407.02067},
        archivePrefix={arXiv},
        primaryClass={cs.CL},
        url={https://arxiv.org/abs/2407.02067},
  }</code></pre>

    </div>
  </section>



  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <!-- <a class="icon-link"
          href="https://arxiv.org/pdf/2310.17586.pdf"> -->
        <a class="icon-link"
          href="https://www.arxiv.org/pdf/2407.02067">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/iamshnoo/crossroads" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a
                href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
              we just ask that you link back to this page in the footer.
              Please remember to remove the analytics code included in the header of the website which
              you do not want on your website.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
